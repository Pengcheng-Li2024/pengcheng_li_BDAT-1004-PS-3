{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f75d8e1-1f21-4df0-ba02-84758f7ee7d2",
   "metadata": {},
   "source": [
    "Question 1\n",
    "Introduction:\n",
    "Special thanks to: https://github.com/justmarkham for sharing the dataset and materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38316de-6aec-471b-b94f-841fd07a7cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n",
    "users = pd.read_csv(url, sep='|') \n",
    "\n",
    "# Step 3\n",
    "print(\"Dataset Overview:\")\n",
    "print(users.head()) \n",
    "\n",
    "# Step 4\n",
    "mean_age_per_occupation = users.groupby('occupation')['age'].mean()\n",
    "print(\"\\nMean age per occupation:\")\n",
    "print(mean_age_per_occupation)\n",
    "\n",
    "# Step 5\n",
    "male_ratio_per_occupation = users.groupby('occupation')['gender'].apply(\n",
    "    lambda x: (x == 'M').sum() / len(x)\n",
    ").sort_values(ascending=False)\n",
    "print(\"\\nMale ratio per occupation (sorted):\")\n",
    "print(male_ratio_per_occupation)\n",
    "\n",
    "# Step 6\n",
    "min_max_age_per_occupation = users.groupby('occupation')['age'].agg(['min', 'max'])\n",
    "print(\"\\nMinimum and maximum ages per occupation:\")\n",
    "print(min_max_age_per_occupation)\n",
    "\n",
    "# Step 7\n",
    "mean_age_per_occupation_gender = users.groupby(['occupation', 'gender'])['age'].mean()\n",
    "print(\"\\nMean age for each combination of occupation and gender:\")\n",
    "print(mean_age_per_occupation_gender)\n",
    "\n",
    "# Step 8\n",
    "gender_counts = users.groupby(['occupation', 'gender']).size().unstack(fill_value=0)\n",
    "gender_counts['Total'] = gender_counts.sum(axis=1)\n",
    "gender_counts['Male%'] = (gender_counts['M'] / gender_counts['Total']) * 100\n",
    "gender_counts['Female%'] = (gender_counts['F'] / gender_counts['Total']) * 100\n",
    "\n",
    "print(\"\\nPercentage of women and men per occupation:\")\n",
    "print(gender_counts[['Male%', 'Female%']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20af73-be33-4430-8b4d-ccc7ff347468",
   "metadata": {},
   "source": [
    "Question 2\n",
    "Euro Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d926d-3d68-4ba7-8daf-a05c731f4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2\n",
    "url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/02_Filtering_%26_Sorting/Euro12/Euro_2012_stats_TEAM.csv'\n",
    "euro12 = pd.read_csv(url)\n",
    "\n",
    "# Step 3\n",
    "print(\"Dataset Overview:\")\n",
    "print(euro12.head()) \n",
    "\n",
    "# Step 4\n",
    "goals = euro12['Goals']\n",
    "print(\"\\nGoals Column:\")\n",
    "print(goals)\n",
    "\n",
    "# Step 5\n",
    "num_teams = euro12['Team'].nunique()\n",
    "print(f\"\\nNumber of teams that participated in Euro 2012: {num_teams}\")\n",
    "\n",
    "# Step 6\n",
    "num_columns = euro12.shape[1]\n",
    "print(f\"\\nNumber of columns in the dataset: {num_columns}\")\n",
    "\n",
    "# Step 7\n",
    "discipline = euro12[['Team', 'Yellow Cards', 'Red Cards']]\n",
    "print(\"\\nDiscipline DataFrame:\")\n",
    "print(discipline)\n",
    "\n",
    "# Step 8\n",
    "sorted_discipline = discipline.sort_values(by=['Red Cards', 'Yellow Cards'], ascending=[True, True])\n",
    "print(\"\\nTeams sorted by Red Cards and then Yellow Cards:\")\n",
    "print(sorted_discipline)\n",
    "\n",
    "# Step 9\n",
    "mean_yellow_cards = discipline['Yellow Cards'].mean()\n",
    "print(f\"\\nMean Yellow Cards given per team: {mean_yellow_cards:.2f}\")\n",
    "\n",
    "# Step 10\n",
    "teams_scored_more_than_6 = euro12[euro12['Goals'] > 6]['Team']\n",
    "print(\"\\nTeams that scored more than 6 goals:\")\n",
    "print(teams_scored_more_than_6)\n",
    "\n",
    "# Step 11\n",
    "teams_start_with_G = euro12[euro12['Team'].str.startswith('G')]\n",
    "print(\"\\nTeams that start with 'G':\")\n",
    "print(teams_start_with_G)\n",
    "\n",
    "# Step 12\n",
    "first_7_columns = euro12.iloc[:, :7]\n",
    "print(\"\\nFirst 7 columns of the dataset:\")\n",
    "print(first_7_columns)\n",
    "\n",
    "# Step 13\n",
    "all_except_last_3 = euro12.iloc[:, :-3]\n",
    "print(\"\\nAll columns except the last 3:\")\n",
    "print(all_except_last_3)\n",
    "\n",
    "# Step 14\n",
    "shooting_accuracy_selected_teams = euro12[euro12['Team'].isin(['England', 'Italy', 'Russia'])][['Team', 'Shooting Accuracy']]\n",
    "print(\"\\nShooting Accuracy for England, Italy, and Russia:\")\n",
    "print(shooting_accuracy_selected_teams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd743a1-a287-40af-881f-73be30d70ef7",
   "metadata": {},
   "source": [
    "Question 3\n",
    "Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231369dd-5a21-48a8-b667-b331e473736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 2\n",
    "np.random.seed(42) \n",
    "series1 = pd.Series(np.random.randint(1, 5, size=100)) \n",
    "series2 = pd.Series(np.random.randint(1, 4, size=100)) \n",
    "series3 = pd.Series(np.random.randint(10000, 30001, size=100)) \n",
    "\n",
    "# Step 3\n",
    "df = pd.concat([series1, series2, series3], axis=1)\n",
    "\n",
    "# Step 4\n",
    "df.columns = ['bedrs', 'bathrs', 'price_sqr_meter']\n",
    "print(\"\\nDataFrame with renamed columns:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 5\n",
    "bigcolumn = pd.DataFrame(pd.concat([series1, series2, series3], ignore_index=True))\n",
    "bigcolumn.columns = ['bigcolumn']\n",
    "print(\"\\nOne-column DataFrame (bigcolumn):\")\n",
    "print(bigcolumn)\n",
    "\n",
    "# Step 6\n",
    "print(\"\\nCheck the index of 'bigcolumn':\")\n",
    "print(bigcolumn.index)\n",
    "\n",
    "# Step 7\n",
    "bigcolumn = bigcolumn.reindex(range(300))\n",
    "print(\"\\nReindexed DataFrame (0 to 299):\")\n",
    "print(bigcolumn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492fad18-7058-4bc3-ab48-e29a28b1c297",
   "metadata": {},
   "source": [
    "Question 4\n",
    "Wind Statistics\n",
    "The data have been modified to contain some missing values, identified by NaN.\n",
    "Using pandas should make this exercise easier, in particular for the bonus question.\n",
    "You should be able to perform all of these operations without using a for loop or other looping construct.\n",
    "The data in 'wind.data' has the following format:\n",
    "Yr Mo Dy RPT VAL ROS KIL SHA BIR DUB CLA MUL CLO BEL MAL\n",
    "61 1 1 15.04 14.96 13.17 9.29 NaN 9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
    "61 1 2 14.71 NaN 10.83 6.50 12.62 7.67 11.50 10.04 9.79 9.67 17.54 13.83\n",
    "61 1 3 18.50 16.88 12.33 10.13 11.17 6.17 11.25 NaN 8.50 7.67 12.75 12.71\n",
    "The first three columns are year, month, and day. The remaining 12 columns are average windspeeds in knots at 12 locations in Ireland on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91e302-e842-4407-8bb2-d850a2c395e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 2\n",
    "file_path = 'wind.txt' \n",
    "data = pd.read_csv(file_path, delim_whitespace=True)\n",
    "\n",
    "# Step 3\n",
    "data['date'] = pd.to_datetime(data[['Yr', 'Mo', 'Dy']].rename(columns={'Yr': 'year', 'Mo': 'month', 'Dy': 'day'}))\n",
    "data = data.drop(['Yr', 'Mo', 'Dy'], axis=1)\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# Step 4\n",
    "def fix_year(year):\n",
    "    return year - 100 if year > 2000 else year\n",
    "\n",
    "data.index = data.index.map(lambda x: x.replace(year=fix_year(x.year)))\n",
    "\n",
    "# Step 5\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "# Step 6\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing values for each location:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Step 7\n",
    "non_missing_values = data.notnull().sum().sum()\n",
    "print(f\"\\nTotal non-missing values: {non_missing_values}\")\n",
    "\n",
    "# Step 8\n",
    "mean_windspeed = data.mean().mean()\n",
    "print(f\"\\nMean windspeed over all locations and times: {mean_windspeed:.2f}\")\n",
    "\n",
    "# Step 9\n",
    "loc_stats = data.aggregate(['min', 'max', 'mean', 'std']).T\n",
    "print(\"\\nLocation statistics (min, max, mean, std):\")\n",
    "print(loc_stats)\n",
    "\n",
    "# Step 10\n",
    "day_stats = data.aggregate(['min', 'max', 'mean', 'std'], axis=1)\n",
    "print(\"\\nDay statistics (min, max, mean, std):\")\n",
    "print(day_stats)\n",
    "\n",
    "# Step 11\n",
    "january_data = data[data.index.month == 1]\n",
    "january_avg = january_data.mean()\n",
    "print(\"\\nAverage windspeed in January for each location:\")\n",
    "print(january_avg)\n",
    "\n",
    "# Step 12\n",
    "yearly_data = data.resample('Y').mean()\n",
    "print(\"\\nYearly frequency downsampled data:\")\n",
    "print(yearly_data)\n",
    "\n",
    "# Step 13\n",
    "monthly_data = data.resample('M').mean()\n",
    "print(\"\\nMonthly frequency downsampled data:\")\n",
    "print(monthly_data)\n",
    "\n",
    "# Step 14\n",
    "weekly_data = data.resample('W').mean()\n",
    "print(\"\\nWeekly frequency downsampled data:\")\n",
    "print(weekly_data)\n",
    "\n",
    "# Step 15\n",
    "weekly_stats = data.resample('W-MON').apply(['min', 'max', 'mean', 'std']).iloc[:52]\n",
    "print(\"\\nWeekly statistics for the first 52 weeks (min, max, mean, std):\")\n",
    "print(weekly_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddb4fd-2e41-416e-8a29-ff0a6f3a3592",
   "metadata": {},
   "source": [
    "Question 5\n",
    "Step 1. Import the necessary libraries\n",
    "Step 2. Import the dataset from this address.\n",
    "Step 3. Assign it to a variable called chipo.\n",
    "Step 4. See the first 10 entries\n",
    "Step 5. What is the number of observations in the dataset?\n",
    "Step 6. What is the number of columns in the dataset?\n",
    "Step 7. Print the name of all the columns.\n",
    "Step 8. How is the dataset indexed?\n",
    "Step 9. Which was the most-ordered item?\n",
    "Step 10. For the most-ordered item, how many items were ordered?\n",
    "Step 11. What was the most ordered item in the choice_description column?\n",
    "Step 12. How many items were orderd in total?\n",
    "Step 13.\n",
    "• Turn the item price into a float\n",
    "• Check the item price type\n",
    "• Create a lambda function and change the type of item price\n",
    "• Check the item price type\n",
    "Step 14. How much was the revenue for the period in the dataset?\n",
    "Step 15. How many orders were made in the period?\n",
    "Step 16. What is the average revenue amount per order?\n",
    "Step 17. How many different items are sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122df610-d609-4fe9-9d78-858b9405a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv'\n",
    "chipo = pd.read_csv(url, sep='\\t') \n",
    "\n",
    "# Step 3\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(chipo.head()) \n",
    "\n",
    "# Step 4\n",
    "print(\"\\nFirst 10 entries:\")\n",
    "print(chipo.head(10))\n",
    "\n",
    "# Step 5\n",
    "num_observations = chipo.shape[0]\n",
    "print(f\"\\nNumber of observations in the dataset: {num_observations}\")\n",
    "\n",
    "# Step 6\n",
    "num_columns = chipo.shape[1]\n",
    "print(f\"\\nNumber of columns in the dataset: {num_columns}\")\n",
    "\n",
    "# Step 7\n",
    "columns = chipo.columns\n",
    "print(\"\\nColumn names:\")\n",
    "print(columns)\n",
    "\n",
    "# Step 8\n",
    "index = chipo.index\n",
    "print(\"\\nDataset index:\")\n",
    "print(index)\n",
    "\n",
    "# Step 9\n",
    "most_ordered_item = chipo.groupby('item_name')['quantity'].sum().idxmax()\n",
    "print(f\"\\nMost-ordered item: {most_ordered_item}\")\n",
    "\n",
    "# Step 10\n",
    "most_ordered_item_quantity = chipo.groupby('item_name')['quantity'].sum().max()\n",
    "print(f\"\\nQuantity of the most-ordered item: {most_ordered_item_quantity}\")\n",
    "\n",
    "# Step 11\n",
    "most_ordered_choice = chipo.groupby('choice_description')['quantity'].sum().idxmax()\n",
    "print(f\"\\nMost ordered item in the choice_description column: {most_ordered_choice}\")\n",
    "\n",
    "# Step 12\n",
    "total_items_ordered = chipo['quantity'].sum()\n",
    "print(f\"\\nTotal items ordered: {total_items_ordered}\")\n",
    "\n",
    "# Step 13\n",
    "# Remove the dollar sign and convert to float\n",
    "chipo['item_price'] = chipo['item_price'].apply(lambda x: float(x[1:]))\n",
    "print(\"\\nItem price converted to float:\")\n",
    "print(chipo['item_price'].head())\n",
    "\n",
    "print(f\"\\nItem price data type after conversion: {chipo['item_price'].dtype}\")\n",
    "\n",
    "# Step 14\n",
    "revenue = (chipo['quantity'] * chipo['item_price']).sum()\n",
    "print(f\"\\nTotal revenue for the period: ${revenue:.2f}\")\n",
    "\n",
    "# Step 15\n",
    "total_orders = chipo['order_id'].nunique()\n",
    "print(f\"\\nTotal orders made: {total_orders}\")\n",
    "\n",
    "# Step 16\n",
    "average_revenue_per_order = revenue / total_orders\n",
    "print(f\"\\nAverage revenue per order: ${average_revenue_per_order:.2f}\")\n",
    "\n",
    "# Step 17\n",
    "different_items_sold = chipo['item_name'].nunique()\n",
    "print(f\"\\nNumber of different items sold: {different_items_sold}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e84a5f-41e0-422f-8f3c-94911d9d904d",
   "metadata": {},
   "source": [
    "Question 6\n",
    "Create a line plot showing the number of marriages and divorces per capita in the U.S. between 1867 and 2014. Label both lines and show the legend.\n",
    "Don't forget to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fb655-718f-46ae-b426-2f7fc0d59dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    \"Year\": range(1867, 2015),\n",
    "    \"Marriages_per_capita\": [1.5 + (x % 10) * 0.05 for x in range(1867, 2015)],\n",
    "    \"Divorces_per_capita\": [0.5 + (x % 15) * 0.03 for x in range(1867, 2015)],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df[\"Year\"], df[\"Marriages_per_capita\"], label=\"Marriages per Capita\", linestyle='-', linewidth=2, color='blue')\n",
    "plt.plot(df[\"Year\"], df[\"Divorces_per_capita\"], label=\"Divorces per Capita\", linestyle='--', linewidth=2, color='red')\n",
    "\n",
    "plt.title(\"Marriages and Divorces per Capita in the U.S. (1867–2014)\", fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Per Capita Count\", fontsize=12)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2bb18-67f3-4828-9509-f53d10a74eb2",
   "metadata": {},
   "source": [
    "Question 7\n",
    "Create a vertical bar chart comparing the number of marriages and divorces per capita in the U.S. between 1900, 1950, and 2000.\n",
    "Don't forget to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f377a3b2-78fe-4083-8988-ef638c4e20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Year\": [1900, 1950, 2000],\n",
    "    \"Marriages_per_capita\": [10.2, 11.8, 8.9],\n",
    "    \"Divorces_per_capita\": [0.9, 2.6, 4.0],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "x = range(len(df[\"Year\"]))\n",
    "bar_width = 0.4\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, df[\"Marriages_per_capita\"], width=bar_width, label=\"Marriages per Capita\", color=\"blue\")\n",
    "plt.bar([pos + bar_width for pos in x], df[\"Divorces_per_capita\"], width=bar_width, label=\"Divorces per Capita\", color=\"red\")\n",
    "\n",
    "plt.title(\"Marriages and Divorces per Capita in the U.S. (1900, 1950, 2000)\", fontsize=14)\n",
    "plt.xlabel(\"Year\", fontsize=12)\n",
    "plt.ylabel(\"Per Capita Count\", fontsize=12)\n",
    "plt.xticks([pos + bar_width / 2 for pos in x], df[\"Year\"])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d73104-2c0f-4e02-8068-12cea83f4173",
   "metadata": {},
   "source": [
    "Question 8\n",
    "Create a horizontal bar chart that compares the deadliest actors in Hollywood. Sort the actors by their kill count and label each bar with the corresponding actor's name. Don't forget to label your axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ef617-8db3-4f13-9e5d-bd47ee3c19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Actor\": [\"Arnold Schwarzenegger\", \"Sylvester Stallone\", \"Bruce Willis\", \"Keanu Reeves\", \"Clint Eastwood\"],\n",
    "    \"Kill Count\": [500, 450, 300, 250, 200],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.sort_values(by=\"Kill Count\", ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df[\"Actor\"], df[\"Kill Count\"], color=\"darkred\")\n",
    "\n",
    "plt.title(\"Deadliest Actors in Hollywood\", fontsize=14)\n",
    "plt.xlabel(\"Kill Count\", fontsize=12)\n",
    "plt.ylabel(\"Actor\", fontsize=12)\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a2ea82-76d7-4bc2-8929-9ade0774678c",
   "metadata": {},
   "source": [
    "Question 9\n",
    "Create a pie chart showing the fraction of all Roman Emperors that were assassinated.\n",
    "Make sure that the pie chart is an even circle, labels the categories, and shows the percentage breakdown of the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc1527-f36d-477b-8c50-f643881b612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    \"Fate\": [\"Assassinated\", \"Other\"],\n",
    "    \"Count\": [50, 150],\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(\n",
    "    data[\"Count\"],\n",
    "    labels=data[\"Fate\"],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=[\"red\", \"gold\"],\n",
    "    wedgeprops={\"edgecolor\": \"black\"},\n",
    ")\n",
    "\n",
    "plt.title(\"Fraction of Roman Emperors Assassinated\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ff8a2-65a0-4043-9892-3e37942fe1a7",
   "metadata": {},
   "source": [
    "Question 10\n",
    "Create a scatter plot showing the relationship between the total revenue earned by arcades and the number of Computer Science PhDs awarded in the U.S. between 2000 and 2009.\n",
    "Don't forget to label your axes!\n",
    "Color each dot according to its year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe5982-0e60-4528-94b9-15e4c3975d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    \"Year\": range(2000, 2010),\n",
    "    \"Arcade_Revenue\": [1.2, 1.4, 1.8, 2.0, 2.2, 2.5, 2.3, 2.8, 3.0, 3.1],\n",
    "    \"CS_PhDs_Awarded\": [800, 850, 900, 950, 1000, 1100, 1050, 1150, 1200, 1250],\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(\n",
    "    data[\"Arcade_Revenue\"],\n",
    "    data[\"CS_PhDs_Awarded\"],\n",
    "    c=data[\"Year\"],\n",
    "    cmap=\"viridis\",\n",
    "    s=100,\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label(\"Year\", fontsize=12)\n",
    "\n",
    "plt.title(\"Arcade Revenue vs. CS PhDs Awarded (2000–2009)\", fontsize=14)\n",
    "plt.xlabel(\"Arcade Revenue (in billions)\", fontsize=12)\n",
    "plt.ylabel(\"CS PhDs Awarded\", fontsize=12)\n",
    "plt.grid(alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
